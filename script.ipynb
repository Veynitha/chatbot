{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Package Installation\n",
    "\n",
    "This section installs and upgrades all the required Python libraries used to build and run the chatbot system. These tools are essential for handling document processing, language model interaction, UI rendering, and environment management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\veyni\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-pptx in c:\\users\\veyni\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\veyni\\anaconda3\\lib\\site-packages (from python-pptx) (10.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\veyni\\anaconda3\\lib\\site-packages (from python-pptx) (3.2.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\veyni\\anaconda3\\lib\\site-packages (from python-pptx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\veyni\\anaconda3\\lib\\site-packages (from python-pptx) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "%pip install -qU \"langchain[google-genai]\"\n",
    "%pip install -qU langchain-huggingface\n",
    "%pip install -qU langchain-core\n",
    "%pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence\n",
    "%pip install python-dotenv\n",
    "%pip install gradio --quiet\n",
    "%pip install python-pptx\n",
    "%pip install -qU langchain_community pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Module Imports and Environment Setup\n",
    "\n",
    "This section imports all necessary Python modules and libraries required for building the chatbot's backend logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from pptx import Presentation\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Environment Variable Setup\n",
    "\n",
    "This block sets up required environment variables and retrieves sensitive keys from the `.env` file. These keys are used to authenticate with third-party services like LangSmith, Google Gemini, and Azure Document Intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "document_intelligence_key = os.getenv(\"DOCUMENTAI_API_KEY\")\n",
    "file_path = \"test.pptx\"\n",
    "endpoint = os.getenv(\"DOCUMENTAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model - Gemini GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings model - HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Vector Model - LangChain Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“„ Document Loading, Splitting, Vectorization & RAG Pipeline Setup\n",
    "\n",
    "This section performs four major tasks:\n",
    "1. Loads and parses the input document using Azure Document Intelligence.\n",
    "2. Splits the parsed content into manageable chunks.\n",
    "3. Embeds the chunks and adds them to an in-memory vector store.\n",
    "4. Builds a retrieval-augmented generation (RAG) reasoning pipeline using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Document Intelligence - Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = AzureAIDocumentIntelligenceLoader(\n",
    "#     api_endpoint=endpoint, api_key=document_intelligence_key, file_path=file_path, api_model=\"prebuilt-layout\"\n",
    "# )\n",
    "\n",
    "# docs = loader.load()\n",
    "# print(f\"Loaded {len(docs)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_path: str) -> list[Document]:\n",
    "    \"\"\"Load a PPTX or PDF into a list of LangChain Document objects.\"\"\"\n",
    "    docs: list[Document] = []\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        print(f\"Loaded {len(docs)} pages into {len(docs)} Document objects.\")\n",
    "\n",
    "    elif ext in (\".pptx\", \".ppt\"):\n",
    "        prs = Presentation(file_path)\n",
    "        for i, slide in enumerate(prs.slides):\n",
    "            slide_texts = []\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\") and shape.text:\n",
    "                    slide_texts.append(shape.text.strip())\n",
    "                elif hasattr(shape, \"text_frame\") and shape.text_frame.text:\n",
    "                    slide_texts.append(shape.text_frame.text.strip())\n",
    "            full_text = \"\\n\".join(slide_texts)\n",
    "            if full_text:\n",
    "                docs.append(Document(page_content=full_text, metadata={\"slide_index\": i}))\n",
    "        print(f\"Loaded {len(docs)} slides into {len(docs)} Document objects.\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 slides into 20 Document objects.\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents(file_path)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Gradio Interface for Chatbot Interaction\n",
    "\n",
    "This section defines the function used to process user questions and launches a Gradio interface for easy interaction with the chatbot via a web-based UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat_fn(question: str) -> str:\n",
    "    result = graph.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=chat_fn,\n",
    "    inputs=gr.Textbox(lines=3, placeholder=\"Type your question hereâ€¦\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\"),\n",
    "    title=\"ðŸ“„ CTSE Document Q & A Chatbot\",\n",
    "    description=\"Ask away!\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True, inline=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
